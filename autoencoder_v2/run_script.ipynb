{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/antares_raid/home/oliver/adhara/src/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/mnt/antares_raid/home/oliver/adhara/src/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/mnt/antares_raid/home/oliver/adhara/src/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/antares_raid/home/oliver/nideep')\n",
    "sys.path.append('/mnt/antares_raid/home/oliver/Scripts/autoencoder')\n",
    "import os\n",
    "from TransformMNIST import MNISTtransformer\n",
    "import subprocess\n",
    "import sys\n",
    "import caffe\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from nideep.eval.learning_curve import LearningCurve\n",
    "from nideep.eval.inference import infer_to_h5_fixed_dims, infer_to_lmdb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_up_dir(path):\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_lmdb_dir = '/mnt/antares_raid/home/oliver/adhara/src/caffe/examples/mnist/'\n",
    "home_dir = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/'\n",
    "set_up_dir(home_dir)\n",
    "dst_lmdb_dir = home_dir + 'MNIST_lmdb/'\n",
    "set_up_dir(dst_lmdb_dir)\n",
    "N_ims = [60000, 10000]\n",
    "angles = range(-90,90+1,15)\n",
    "batch_size = 1000.\n",
    "set_strings = ['_TRAIN_', '_TEST_']\n",
    "dir_strings = ['_train_', '_test_']\n",
    "\n",
    "if False:\n",
    "    # Create the lmdb database\n",
    "    for set_str, dir_str, N_im in zip(set_strings, dir_strings,N_ims):\n",
    "        mnisttransform = MNISTtransformer(src_lmdb_dir, home_dir, dst_lmdb_dir, N_im, batch_size, set_str, dir_str, angles)\n",
    "        mnisttransform.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train autoencoder weights\n",
    "#p = subprocess.Popen([\"screen\"])\n",
    "#p = subprocess.Popen([\"/mnt/antares_raid/home/oliver/adhara/src/caffe/build/tools/caffe\", \"train\", \"-solver\", \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/autoencoder_net_solver.prototxt\"])\n",
    "\n",
    "#/mnt/antares_raid/home/oliver/adhara/src/caffe/build/tools/caffe train -solver /mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/autoencoder_net_solver.prototxt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check weights\n",
    "\n",
    "proto = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/deploy_autoencoder_net.prototxt'\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/snapshots/_iter_156000.caffemodel'\n",
    "lmdb_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/MNIST_lmdb/MNIST_TEST_10000_rot_lmdb/shuffled/'\n",
    "\n",
    "proto = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/deploy_autoencoder_with_MLP_net.prototxt'\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/snapshots_with_MLP/_iter_780000.caffemodel'\n",
    "lmdb_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/MNIST_lmdb/MNIST_TEST_10000_rot_lmdb/shuffled/'\n",
    "\n",
    "net = caffe.Net(proto, model, caffe.TEST)\n",
    "\n",
    "\n",
    "count = 0\n",
    "correct = 0\n",
    "matrix = defaultdict(int) # (real,pred) -> int\n",
    "labels_set = set()\n",
    "\n",
    "net = caffe.Net(proto, model, caffe.TEST)\n",
    "caffe.set_mode_cpu()\n",
    "lmdb_env = lmdb.open(lmdb_path)\n",
    "lmdb_txn = lmdb_env.begin()\n",
    "lmdb_cursor = lmdb_txn.cursor()\n",
    "for key, value in lmdb_cursor:\n",
    "    datum = caffe.proto.caffe_pb2.Datum()\n",
    "    datum.ParseFromString(value)\n",
    "    label = int(datum.label)\n",
    "    image = caffe.io.datum_to_array(datum)\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    out = net.forward_all(data=np.asarray([image]))\n",
    "    plabel = int(out['score'][0].argmax(axis=0))\n",
    "\n",
    "    count = count + 1\n",
    "    iscorrect = label == plabel\n",
    "    correct = correct + (1 if iscorrect else 0)\n",
    "    matrix[(label, plabel)] += 1\n",
    "    labels_set.update([label, plabel])\n",
    "\n",
    "    #if not iscorrect:\n",
    "    #    print(\"\\rError: key=%s, expected %i but predicted %i\" \\\n",
    "    #            % (key, label, plabel))\n",
    "\n",
    "    #sys.stdout.write(\"\\rAccuracy: %.1f%%\" % (100.*correct/count))\n",
    "    #sys.stdout.flush()\n",
    "    \n",
    "    plt.figure(figsize=(18,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image.reshape(28, 28).T, cmap='gray'); plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.title('Input')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.array([sigmoid(a) for a  in out['decode1'].squeeze()]).reshape(28, 28).T, cmap='gray'); plt.axis('off')\n",
    "    plt.title('decode1 output')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    if count == 5:\n",
    "        break\n",
    "#print(str(correct) + \" out of \" + str(count) + \" were classified correctly\")\n",
    "\n",
    "print \"\"\n",
    "print \"Confusion matrix:\"\n",
    "print \"(r , p) | count\"\n",
    "for l in labels_set:\n",
    "    for pl in labels_set:\n",
    "        print \"(%i , %i) | %i\" % (l, pl, matrix[(l,pl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Autoencoder + MLP\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/snapshots_28_07/_iter_702000.caffemodel'\n",
    "\n",
    "#p = subprocess.Popen([\"screen\"])\n",
    "#p = subprocess.Popen([\"/mnt/antares_raid/home/oliver/adhara/src/caffe/build/tools/caffe\", \"train\", \n",
    "#\"-solver\", \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/autoencoder_with_MLP_solver.prototxt\",\"-weights\", \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/snapshots_28_07/_iter_702000.caffemodel\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blobs ['data', 'label', 'data_unrot', 'label_unrot', 'flatdata_unrot', 'encode1', 'encode1neuron', 'encode2', 'encode2neuron', 'encode3', 'encode3neuron', 'encode4', 'encode4neuron', 'score']\n",
      "params ['encode1', 'encode2', 'encode3', 'encode4', 'score']\n"
     ]
    }
   ],
   "source": [
    "# Use Youssef Script to save results to hdf5\n",
    "proto = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/autoencoder_with_MLP_net.prototxt'\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/snapshots_with_MLP/_iter_780000.caffemodel'\n",
    "lmdb_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/MNIST_lmdb/MNIST_TRAIN_60000_rot_lmdb/shuffled/'\n",
    "\n",
    "net = caffe.Net(proto, model, caffe.TRAIN)\n",
    "#print(list(net._layer_names))\n",
    "\n",
    "keys = ['label', 'score', 'data']\n",
    "dst_fpath =  \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/results/res_train.hdf5\"\n",
    "n = 780\n",
    "infer_to_h5_fixed_dims(net, keys, n, dst_fpath, preserve_batch=False)\n",
    "\n",
    "# Use encoding weights to train an MLP\n",
    "\n",
    "dst_prefix =  '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/results/%s'\n",
    "print(\"blobs {}\\nparams {}\".format(net.blobs.keys(), net.params.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(dst_fpath, \"r\")\n",
    "#for name in f:\n",
    "#    a = f[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.98      0.98     76999\n",
      "        1.0       0.98      0.98      0.98     87646\n",
      "        2.0       0.94      0.95      0.94     77454\n",
      "        3.0       0.94      0.92      0.93     79703\n",
      "        4.0       0.94      0.95      0.94     75946\n",
      "        5.0       0.93      0.93      0.93     70473\n",
      "        6.0       0.95      0.95      0.95     76934\n",
      "        7.0       0.94      0.93      0.94     81445\n",
      "        8.0       0.93      0.94      0.93     76063\n",
      "        9.0       0.91      0.90      0.91     77337\n",
      "\n",
      "avg / total       0.94      0.94      0.94    780000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[75518,    12,   196,   132,    14,   226,   360,    32,   378,\n",
       "          131],\n",
       "       [    0, 86030,   540,   196,   220,    65,    53,   213,   280,\n",
       "           49],\n",
       "       [  291,   233, 73308,   459,   717,    69,   201,  1177,   880,\n",
       "          119],\n",
       "       [  189,   133,  1226, 73413,    76,  1505,   278,   602,  1676,\n",
       "          605],\n",
       "       [   74,   123,   370,   176, 71833,   548,   336,   429,   499,\n",
       "         1558],\n",
       "       [  337,   106,   164,   999,   452, 65518,  1147,   484,   650,\n",
       "          616],\n",
       "       [  281,   141,   235,   239,   262,   862, 73011,   240,   304,\n",
       "         1359],\n",
       "       [  142,   435,  1264,   297,  1021,   313,   154, 76072,   174,\n",
       "         1573],\n",
       "       [  204,   540,   615,  1222,   706,   502,   357,   225, 71139,\n",
       "          553],\n",
       "       [  408,   222,   243,   944,  1345,   891,  1263,  1377,   800,\n",
       "        69844]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [np.argmax(p) for p in f['score']]\n",
    "true = list(f['label']) \n",
    "print(classification_report(true,pred))\n",
    "confusion_matrix(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
