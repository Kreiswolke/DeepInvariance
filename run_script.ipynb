{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/antares_raid/home/oliver/nideep')\n",
    "sys.path.append('/mnt/antares_raid/home/oliver/Scripts/autoencoder')\n",
    "import os\n",
    "from TransformMNIST import MNISTtransformer\n",
    "from CorruptMNIST import MNISTcorrupter\n",
    "import subprocess\n",
    "import sys\n",
    "import caffe\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from nideep.eval.learning_curve import LearningCurve\n",
    "from nideep.eval.inference import infer_to_h5_fixed_dims, infer_to_lmdb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nideep.eval.learning_curve import LearningCurve\n",
    "from nideep.eval.eval_utils import Phase\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_up_dir(path):\n",
    "    try: \n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CREATE MNIST ROT/UNROT\n",
    "src_lmdb_dir = '/mnt/antares_raid/home/oliver/adhara/src/caffe/examples/mnist/'\n",
    "dst_lmdb_dir = '/mnt/antares_raid/home/oliver/Experiments/lmdbs/'\n",
    "#set_up_dir(home_dir)\n",
    "#dst_lmdb_dir = home_dir + 'MNIST_lmdb/'\n",
    "set_up_dir(dst_lmdb_dir)\n",
    "N_ims = [60000, 10000]\n",
    "angles = range(-90,90+1,15)\n",
    "batch_size = 1000.\n",
    "set_strings = ['_TRAIN_', '_TEST_']\n",
    "dir_strings = ['_train_', '_test_']\n",
    "\n",
    "if True:\n",
    "    # Create the lmdb database\n",
    "    for set_str, dir_str, N_im in zip(set_strings, dir_strings,N_ims):\n",
    "        mnisttransform = MNISTtransformer(src_lmdb_dir, dst_lmdb_dir, N_im, batch_size, set_str, dir_str, angles)\n",
    "        mnisttransform.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CREATE MNIST ROT/UNROT + CORRUPTED\n",
    "src_lmdb_dir = '/mnt/antares_raid/home/oliver/adhara/src/caffe/examples/mnist/'\n",
    "home_dir = '/mnt/antares_raid/home/oliver/Experiments/lmdbs/corr_test/'\n",
    "set_up_dir(home_dir)\n",
    "\n",
    "dst_lmdb_dir = home_dir + 'lmdb_corrupted/'\n",
    "set_up_dir(dst_lmdb_dir)\n",
    "N_ims = [60000, 10000]\n",
    "angles = range(-90,90+1,15)\n",
    "batch_size = 1000.\n",
    "corrupt_ratio = 0.25\n",
    "N_pix_corrupt = np.ceil(corrupt_ratio*28*28)\n",
    "set_strings = ['_TRAIN_', '_TEST_']\n",
    "dir_strings = ['_train_', '_test_']\n",
    "\n",
    "if True:\n",
    "    # Create the lmdb database\n",
    "    for set_str, dir_str, N_im in zip(set_strings, dir_strings,N_ims):\n",
    "        mnisttransform = MNISTcorrupter(src_lmdb_dir, dst_lmdb_dir, N_im, batch_size, set_str, dir_str, angles, N_pix_corrupt)\n",
    "        mnisttransform.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Nr. 10000 created from _train_\n",
      "Image Nr. 20000 created from _train_\n",
      "Image Nr. 30000 created from _train_\n",
      "Image Nr. 40000 created from _train_\n",
      "Image Nr. 50000 created from _train_\n",
      "Image Nr. 60000 created from _train_\n",
      "Image Nr. 70000 created from _train_\n",
      "Image Nr. 80000 created from _train_\n",
      "Image Nr. 90000 created from _train_\n",
      "Image Nr. 100000 created from _train_\n",
      "Image Nr. 110000 created from _train_\n",
      "Image Nr. 120000 created from _train_\n",
      "Image Nr. 130000 created from _train_\n",
      "Image Nr. 140000 created from _train_\n",
      "Image Nr. 150000 created from _train_\n",
      "Image Nr. 160000 created from _train_\n",
      "Image Nr. 170000 created from _train_\n",
      "Image Nr. 180000 created from _train_\n",
      "Image Nr. 190000 created from _train_\n",
      "Image Nr. 200000 created from _train_\n",
      "Image Nr. 210000 created from _train_\n",
      "Image Nr. 220000 created from _train_\n",
      "Image Nr. 230000 created from _train_\n",
      "Image Nr. 240000 created from _train_\n",
      "Image Nr. 250000 created from _train_\n",
      "Image Nr. 260000 created from _train_\n",
      "Image Nr. 270000 created from _train_\n",
      "Image Nr. 280000 created from _train_\n",
      "Image Nr. 290000 created from _train_\n",
      "Image Nr. 300000 created from _train_\n",
      "Image Nr. 310000 created from _train_\n",
      "Image Nr. 320000 created from _train_\n",
      "Image Nr. 330000 created from _train_\n",
      "Image Nr. 340000 created from _train_\n",
      "Image Nr. 350000 created from _train_\n",
      "Image Nr. 360000 created from _train_\n",
      "Image Nr. 370000 created from _train_\n",
      "Image Nr. 380000 created from _train_\n",
      "Image Nr. 390000 created from _train_\n",
      "Image Nr. 400000 created from _train_\n",
      "Image Nr. 410000 created from _train_\n",
      "Image Nr. 420000 created from _train_\n",
      "Image Nr. 430000 created from _train_\n",
      "Image Nr. 440000 created from _train_\n",
      "Image Nr. 450000 created from _train_\n",
      "Image Nr. 460000 created from _train_\n",
      "Image Nr. 470000 created from _train_\n",
      "Image Nr. 480000 created from _train_\n",
      "Image Nr. 490000 created from _train_\n",
      "Image Nr. 500000 created from _train_\n",
      "Image Nr. 510000 created from _train_\n",
      "Image Nr. 520000 created from _train_\n",
      "Image Nr. 530000 created from _train_\n",
      "Image Nr. 540000 created from _train_\n",
      "Image Nr. 550000 created from _train_\n",
      "Image Nr. 560000 created from _train_\n",
      "Image Nr. 570000 created from _train_\n",
      "Image Nr. 580000 created from _train_\n",
      "Image Nr. 590000 created from _train_\n",
      "Image Nr. 600000 created from _train_\n",
      "Image Nr. 610000 created from _train_\n",
      "Image Nr. 620000 created from _train_\n",
      "Image Nr. 630000 created from _train_\n",
      "Image Nr. 640000 created from _train_\n",
      "Image Nr. 650000 created from _train_\n",
      "Image Nr. 660000 created from _train_\n",
      "Image Nr. 670000 created from _train_\n",
      "Image Nr. 680000 created from _train_\n",
      "Image Nr. 690000 created from _train_\n",
      "Image Nr. 700000 created from _train_\n",
      "Image Nr. 710000 created from _train_\n",
      "Image Nr. 720000 created from _train_\n",
      "Image Nr. 730000 created from _train_\n",
      "Image Nr. 740000 created from _train_\n",
      "Image Nr. 750000 created from _train_\n",
      "Image Nr. 760000 created from _train_\n",
      "Image Nr. 770000 created from _train_\n",
      "Image Nr. 780000 created from _train_\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1516c865fc5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_im\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset_strings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_strings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN_ims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mmnisttransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNISTcorrupter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_lmdb_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_lmdb_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_im\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_pix_corrupt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mmnisttransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Created %s lmdb'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mset_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/antares_raid/home/oliver/Scripts/CorruptMNIST.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mdst_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdst_lmdb_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'MNIST'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mset_st\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'rot_lmdb/shuffled'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "#CREATE MNIST ROT/UNROT + CORRUPTED INCLUDING MISSING UNROT_UNCORRUPT \n",
    "src_lmdb_dir = '/mnt/antares_raid/home/oliver/adhara/src/caffe/examples/mnist/'\n",
    "home_dir = '/mnt/antares_raid/home/oliver/Experiments/lmdbs/corrupted_25/'\n",
    "set_up_dir(home_dir)\n",
    "\n",
    "dst_lmdb_dir = home_dir #+ 'lmdb_corrupted/'\n",
    "set_up_dir(dst_lmdb_dir)\n",
    "N_ims = [60000, 10000]\n",
    "angles = range(-90,90+1,15)\n",
    "batch_size = 1000.\n",
    "corrupt_ratio = 0.25\n",
    "N_pix_corrupt = np.ceil(corrupt_ratio*28*28)\n",
    "set_strings = ['_TRAIN_', '_TEST_']\n",
    "dir_strings = ['_train_', '_test_']\n",
    "\n",
    "inds = ['/mnt/antares_raid/home/oliver/Experiments/lmdbs/corrupted_25/indices_list_train.txt',\n",
    "        '/mnt/antares_raid/home/oliver/Experiments/lmdbs/corrupted_25/indices_list_test.txt']\n",
    "\n",
    "if True:\n",
    "    # Create the lmdb database\n",
    "    for ind,set_str, dir_str, N_im in zip(inds,set_strings, dir_strings,N_ims):\n",
    "        mnisttransform = MNISTcorrupter(src_lmdb_dir, dst_lmdb_dir, N_im, batch_size, set_str, dir_str, angles, N_pix_corrupt)\n",
    "        mnisttransform.run()\n",
    "        print('Created %s lmdb'%set_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train autoencoder weights\n",
    "#p = subprocess.Popen([\"screen\"])\n",
    "#p = subprocess.Popen([\"/mnt/antares_raid/home/oliver/adhara/src/caffe/build/tools/caffe\", \"train\", \"-solver\", \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/autoencoder_net_solver.prototxt\"])\n",
    "\n",
    "#/mnt/antares_raid/home/oliver/adhara/src/caffe/build/tools/caffe train -solver /mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/autoencoder_net_solver.prototxt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check weights\n",
    "\n",
    "proto = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/deploy_autoencoder_net.prototxt'\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/snapshots/_iter_156000.caffemodel'\n",
    "lmdb_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/MNIST_lmdb/MNIST_TEST_10000_rot_lmdb/shuffled/'\n",
    "\n",
    "proto = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/deploy_autoencoder_with_MLP_net.prototxt'\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/snapshots_with_MLP/_iter_780000.caffemodel'\n",
    "lmdb_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/MNIST_lmdb/MNIST_TEST_10000_rot_lmdb/shuffled/'\n",
    "\n",
    "net = caffe.Net(proto, model, caffe.TEST)\n",
    "\n",
    "\n",
    "count = 0\n",
    "correct = 0\n",
    "matrix = defaultdict(int) # (real,pred) -> int\n",
    "labels_set = set()\n",
    "\n",
    "net = caffe.Net(proto, model, caffe.TEST)\n",
    "caffe.set_mode_cpu()\n",
    "lmdb_env = lmdb.open(lmdb_path)\n",
    "lmdb_txn = lmdb_env.begin()\n",
    "lmdb_cursor = lmdb_txn.cursor()\n",
    "for key, value in lmdb_cursor:\n",
    "    datum = caffe.proto.caffe_pb2.Datum()\n",
    "    datum.ParseFromString(value)\n",
    "    label = int(datum.label)\n",
    "    image = caffe.io.datum_to_array(datum)\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    out = net.forward_all(data=np.asarray([image]))\n",
    "    plabel = int(out['score'][0].argmax(axis=0))\n",
    "\n",
    "    count = count + 1\n",
    "    iscorrect = label == plabel\n",
    "    correct = correct + (1 if iscorrect else 0)\n",
    "    matrix[(label, plabel)] += 1\n",
    "    labels_set.update([label, plabel])\n",
    "\n",
    "    #if not iscorrect:\n",
    "    #    print(\"\\rError: key=%s, expected %i but predicted %i\" \\\n",
    "    #            % (key, label, plabel))\n",
    "\n",
    "    #sys.stdout.write(\"\\rAccuracy: %.1f%%\" % (100.*correct/count))\n",
    "    #sys.stdout.flush()\n",
    "    \n",
    "    plt.figure(figsize=(18,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image.reshape(28, 28).T, cmap='gray'); plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.title('Input')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.array([sigmoid(a) for a  in out['decode1'].squeeze()]).reshape(28, 28).T, cmap='gray'); plt.axis('off')\n",
    "    plt.title('decode1 output')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    if count == 5:\n",
    "        break\n",
    "#print(str(correct) + \" out of \" + str(count) + \" were classified correctly\")\n",
    "\n",
    "print \"\"\n",
    "print \"Confusion matrix:\"\n",
    "print \"(r , p) | count\"\n",
    "for l in labels_set:\n",
    "    for pl in labels_set:\n",
    "        print \"(%i , %i) | %i\" % (l, pl, matrix[(l,pl)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Autoencoder + MLP\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/snapshots_28_07/_iter_702000.caffemodel'\n",
    "\n",
    "#p = subprocess.Popen([\"screen\"])\n",
    "#p = subprocess.Popen([\"/mnt/antares_raid/home/oliver/adhara/src/caffe/build/tools/caffe\", \"train\", \n",
    "#\"-solver\", \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/autoencoder_with_MLP_solver.prototxt\",\"-weights\", \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder/snapshots_28_07/_iter_702000.caffemodel\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Youssef Script to save results to hdf5\n",
    "proto = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/autoencoder_with_MLP_net.prototxt'\n",
    "model = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/snapshots_with_MLP/_iter_780000.caffemodel'\n",
    "lmdb_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/MNIST_lmdb/MNIST_TRAIN_60000_rot_lmdb/shuffled/'\n",
    "\n",
    "net = caffe.Net(proto, model, caffe.TRAIN)\n",
    "#print(list(net._layer_names))\n",
    "\n",
    "keys = ['label', 'score', 'data']\n",
    "dst_fpath =  \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/results/res_train.hdf5\"\n",
    "n = 780\n",
    "infer_to_h5_fixed_dims(net, keys, n, dst_fpath, preserve_batch=False)\n",
    "\n",
    "# Use encoding weights to train an MLP\n",
    "\n",
    "dst_prefix =  '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/results/%s'\n",
    "print(\"blobs {}\\nparams {}\".format(net.blobs.keys(), net.params.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "dst_fpath =  \"/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP/results/res_train.hdf5\"\n",
    "f = h5py.File(dst_fpath, \"r\")\n",
    "pred = [np.argmax(p) for p in f['score']]\n",
    "true = list(f['label']) \n",
    "print(classification_report(true,pred))\n",
    "conf_mat = confusion_matrix(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow((conf_mat/780000.), interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exps = ['AER', 'AEUR', 'RAND']\n",
    "exp_labels = ['Rotated', 'Unrotated', 'Random']\n",
    "exp_data = {'AER':{'log':'/mnt/antares_raid/home/oliver/Experiments/MLP/AER/log/log.log'} ,\n",
    "            'AEUR':{'log':'/mnt/antares_raid/home/oliver/Experiments/MLP/AEUR/log/log.log'},\n",
    "            'RAND':{'log':'/mnt/antares_raid/home/oliver/Experiments/MLP/RAND/log/log.log'}\n",
    "            }\n",
    "for exp in exps:\n",
    "    e = LearningCurve(exp_data[exp]['log'])\n",
    "    e.parse()\n",
    "    for phase in [Phase.TRAIN, Phase.TEST]:\n",
    "        exp_data[exp][phase] = {}\n",
    "        exp_data[exp][phase]['num_iter'] = e.list('NumIters', phase)\n",
    "        exp_data[exp][phase]['loss'] = e.list('loss', phase)\n",
    "        exp_data[exp][phase]['acc'] = e.list('accuracy', phase)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, exp in enumerate(exps):\n",
    "    plt.subplot(2,1,1)\n",
    "    phase = Phase.TRAIN\n",
    "    plt.plot(exp_data[exp][phase]['num_iter'], exp_data[exp][phase]['loss'], label='AE weights: %s' % (exp_labels[i],))\n",
    "    plt.xlabel('iteration')\n",
    "    # format x-axis ticks\n",
    "    ticks, _ = plt.xticks()\n",
    "    plt.xticks(ticks, [\"%dK\" % int(t/1000) for t in ticks])\n",
    "    plt.ylabel('train loss')\n",
    "    plt.title(\"on %s set\" % (phase,))\n",
    "    plt.legend()\n",
    "    \n",
    "    phase = Phase.TEST\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(exp_data[exp][phase]['num_iter'],exp_data[exp][phase]['acc'], label='AE weights: %s' % (exp_labels[i],))\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title(\"on %s set\" % (phase,))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.figure(figsize=(20,10))\n",
    "for exp in exps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_path = '/mnt/antares_raid/home/oliver/Scripts/autoencoder_v2/autoencoder_with_MLP_logfile/log/20160801.log'\n",
    "log_path = '/mnt/antares_raid/home/oliver/Experiments/MLP/AER/log/log.log'\n",
    "e = LearningCurve(log_path)\n",
    "print(e.path_log)\n",
    "\n",
    "e.parse()\n",
    "plt.figure(figsize=(20,10))\n",
    "for phase in [Phase.TRAIN, Phase.TEST]:\n",
    "    num_iter = e.list('NumIters', phase)\n",
    "    loss = e.list('loss', phase)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(num_iter[:10], loss[:10], label='on %s set' % (phase,))\n",
    "    plt.xlabel('iteration')\n",
    "    # format x-axis ticks\n",
    "    ticks, _ = plt.xticks()\n",
    "    plt.xticks(ticks, [\"%dK\" % int(t/1000) for t in ticks])\n",
    "    plt.ylabel('loss')\n",
    "    plt.title(e.name())\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(num_iter, loss, label='on %s set' % (phase,))\n",
    "    plt.xlabel('iteration')\n",
    "    # format x-axis ticks\n",
    "    ticks, _ = plt.xticks()\n",
    "    plt.xticks(ticks, [\"%dK\" % int(t/1000) for t in ticks])\n",
    "    plt.ylabel('loss')\n",
    "    plt.title(e.name())\n",
    "    plt.legend()\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "num_iter = e.list('NumIters', phase)\n",
    "acc = e.list('accuracy', phase)\n",
    "plt.plot(num_iter, acc, label=e.name())\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"on %s set\" % (phase,))\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(num_iter[:10], acc[:10], label=e.name())\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"on %s set\" % (phase,))\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "A = np.random.randint(0,256, size=(28,28))\n",
    "A = np.eye(28)\n",
    "A[10,2] = 1\n",
    "A[15,4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(A, interpolation='none')\n",
    "rint = np.random.choice(28*28, int(0.25*28*28), replace=False)\n",
    "plt.show()\n",
    "A = A.flatten()\n",
    "A[rint] = 0\n",
    "A = A.reshape((28,28))\n",
    "plt.imshow(A, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST LMDB\n",
    "path = \"/mnt/antares_raid/home/oliver/Experiments/lmdbs/corrupted_50/MNIST_TRAIN_60000_corrupt_px_392_unrot_lmdb/shuffled\"\n",
    "\n",
    "N=10\n",
    "lmdb_env = lmdb.open(path)\n",
    "lmdb_txn = lmdb_env.begin()\n",
    "lmdb_cursor = lmdb_txn.cursor()\n",
    "print(lmdb_env.stat())\n",
    "datum_db = caffe.proto.caffe_pb2.Datum()\n",
    "I = []\n",
    "Label = []\n",
    "im_count = 0\n",
    "for key, value in lmdb_cursor:\n",
    "        datum_db.ParseFromString(value)\n",
    "        label = datum_db.label\n",
    "        data = caffe.io.datum_to_array(datum_db)\n",
    "        #im = data.astype(np.uint8)\n",
    "        #im = np.transpose(im, (2, 1, 0)) # original (dim, col, row)\n",
    "        #plt.imshow(im.squeeze())\n",
    "        #plt.show()\n",
    "        im_count = im_count + 1\n",
    "        im = data.astype(np.uint8)\n",
    "        im = np.transpose(im, (2, 1, 0)) # original (dim, col, row)\n",
    "        plt.imshow(im.squeeze())\n",
    "        plt.show()\n",
    "        if im_count == 10:\n",
    "            break\n",
    "            \n",
    "path = \"/mnt/antares_raid/home/oliver/Experiments/lmdbs/corrupted_50/MNIST_TEST_10000_corrupt_px_392_rot_ang_lmdb/shuffled\"\n",
    "\n",
    "N=10\n",
    "lmdb_env = lmdb.open(path)\n",
    "lmdb_txn = lmdb_env.begin()\n",
    "lmdb_cursor = lmdb_txn.cursor()\n",
    "datum_db = caffe.proto.caffe_pb2.Datum()\n",
    "I = []\n",
    "Label = []\n",
    "im_count = 0\n",
    "for key, value in lmdb_cursor:\n",
    "        print(key,value)\n",
    "        im_count = im_count + 1\n",
    "        if im_count ==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "24*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
